---
title: "STAT/MATH 495: Problem Set 05"
author: "Jenn, Pei, and Anthony"
date: "2017-10-11"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(corrplot)
library(broom)

# Note the relative file path, and not absolute file path:
train <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sampleSubmission.csv")
```


# Notes

In one version of this assignment, we fit a linear model using dplyr. For more information on that, see [this](https://cran.r-project.org/web/packages/broom/vignettes/broom_and_dplyr.html).

# Exploratory Data Analysis

Information on the competition can be found [here](https://www.kaggle.com/c/bike-sharing-demand).

```{r}
# Storing a version of time in system time 
train <- train %>% mutate(SysTime = as.numeric(unclass(datetime)))
test <- test %>% mutate(SysTime = as.numeric(unclass(datetime)))
```

Let's look at our dependent variable: count, the total count of bikes rented during each hour.

```{r, echo = FALSE}
ggplot(data = train) +
  geom_histogram(aes(count)) + 
  labs(x = "num_bikes")
```

Looks like the distribution of bikes rented per hour is seriously skewed right. Let's transform our dependent variable by taking the natural log. 

```{r, echo = FALSE}
train <- train %>% mutate(log_count = log(count))

ggplot(data = train) +
  geom_histogram(aes(log_count)) + 
  labs(x = "log(num_bikes)")
```

This distribution looks a bit closer to normal, although it now appears to be skewed to the left. Still, using the logarithm of count should be better for linear regression.

Note: Since the logarithm of count is our outcome variable, we are interested in variables that have a high correlation with the `log_count`. We do not look at `registered` and `casual` because `count` is just the sum of these two variables.

```{r, echo = FALSE}
corPlotData <- train %>% select(season, holiday, workingday, weather, temp, atemp, humidity, windspeed, log_count, SysTime) %>% cor()
corrplot(corPlotData, order = "hclust")

```

From the correlation plot, `temperature`, dateTime (`SysTime` in the plot), and `humidity` are the three variables that have the strongest relationship with bike rentals. We will use these three predictors to fit our model.

# Model Fit

Fitting the model to the training data. We must again note that the dependent variable is the logairthm of count, not the actual count.

```{r}
model <- lm(log_count ~ SysTime + temp + humidity, data = train)
summary(model)$coefficients %>% knitr::kable(digits = 3)
```

# Create Submission File

We now use our model to make predictions for the test set. We take the exponential of our predicted values for log_count to get back to the original units.

```{r}
fit <- train %>% do(augment(lm(log_count ~ SysTime + temp + humidity, data = .), newdata = test))
dfToSubmit <- fit %>% mutate(count = round(exp(.fitted), 0)) %>% select(datetime, count)

write.csv(dfToSubmit, file = "submission.csv", row.names = FALSE)
```

Sanity check: let's look at the distribution of our predictions. It looks very similar to the distribution of the training set - skewed right and centered close to 0.

```{r, echo = FALSE}
ggplot(data = dfToSubmit) +
  geom_histogram(aes(count)) +
  labs(main = "Distribution of predicted values", x = "num_bikes")
```