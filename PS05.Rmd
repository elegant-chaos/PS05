---
title: "STAT/MATH 495: Problem Set 05"
author: "Jenn, Pei, and Anthony"
date: "2017-10-11"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)

# Load packages
library(tidyverse)
library(corrplot)
library(broom)

# Note the relative file path, and not absolute file path:
train <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
sample_submission <- read_csv("data/sampleSubmission.csv")
```


# Notes

We fit a linear model using dplyr, which we learned about [here](https://cran.r-project.org/web/packages/broom/vignettes/broom_and_dplyr.html).

# Exploratory Data Analysis

Information on the competition can be found [here](https://www.kaggle.com/c/bike-sharing-demand).

```{r}
# Storing a version of time in system time 
train <- train %>% mutate(SysTime = as.numeric(unclass(datetime)))
test <- test %>% mutate(SysTime = as.numeric(unclass(datetime)))
```

Let's look at our dependent variable: count, the total count of bikes rented during each hour.

```{r, echo = FALSE}
ggplot(data = train) +
  geom_histogram(aes(count)) + 
  labs(x = "num_bikes")
```

The histogram shows the distribution of bikes rented per hour has a right skew. We chose to log transform count as a potential fix.

```{r, echo = FALSE}
train <- train %>% mutate(log_count = log(count))

ggplot(data = train) +
  geom_histogram(aes(log_count)) + 
  labs(x = "log(num_bikes)")
```

The histogram of log(count) shows a distribution that looks a bit closer to normal, although some left skew is still displayed. However, the more normal distribution of log(count) should result in better predictions when using linear regression.

Note: Since the logarithm of count is our outcome variable, we are interested in variables that have a high correlation with the `log_count`. We do not look at `registered` and `casual` because `count` is just the sum of these two variables.

```{r, echo = FALSE}
corPlotData <- train %>% select(season, holiday, workingday, weather, temp, atemp, humidity, windspeed, log_count, SysTime) %>% cor()
corrplot(corPlotData, order = "hclust")

```

From the correlation plot, `atemp`, `dateTime` (`SysTime` in the plot), and `humidity` are the three variables that have the strongest relationship with bike rentals. We will use these three predictors to fit our model.


Here, we fit a linear model for `log_count` predicted by the 3 most correlated variables: `atemp`, `dateTime`, and `humidity`.

```{r}
model <- lm(log_count ~ SysTime + atemp + humidity, data = train)
summary(model)$coefficients %>% knitr::kable(digits = 3)
```

# Create Submission File

We now use our model to make predictions for the test set, taking the exponential of `log_count` to transform back to the original units of `count`.

```{r}
fit <- train %>% do(augment(lm(log_count ~ SysTime + atemp + humidity, data = .), newdata = test))
dfToSubmit <- fit %>% mutate(count = round(exp(.fitted), 0)) %>% select(datetime, count)

write.csv(dfToSubmit, file = "submission.csv", row.names = FALSE)
```

Sanity check: let's look at the distribution of our predictions. It looks very similar to the distribution of the training set - skewed right and centered close to 0.

```{r, echo = FALSE}
ggplot(data = dfToSubmit) +
  geom_histogram(aes(count)) +
  labs(main = "Distribution of predicted values", x = "num_bikes")
```

In the end, our model yielded a Kaggle score of 1.20101. 